AI Debugger Copilot â€” Multi-Agent RAG System for Java Errors

An intelligent debugging assistant that analyzes Java errors, retrieves relevant knowledge, generates fixes, validates solutions, and learns from past debugging sessions.

This project demonstrates a production-style multi-agent AI architecture combining Retrieval-Augmented Generation (RAG), reranking, planning agents, and memory-based learning.

ğŸš€ What this project does

Given a Java error like:

ConcurrentModificationException in ArrayList loop


The system:

Understands the error using an AI analyst agent

Plans how to search using a retrieval strategist agent

Retrieves knowledge from vector database

Reranks results using a cross-encoder

Generates multiple fixes with explanation

Validates the solution using a reviewer agent

Learns from the debugging session using memory

ğŸ§  System Architecture
User Error
   â†“
Memory Lookup (past debugging cases)
   â†“
Error Analyst Agent
   â†“
Retrieval Strategist Agent
   â†“
Vector Search (FAISS)
   â†“
Cross-Encoder Reranker
   â†“
Fix Generator Agent
   â†“
Solution Validator Agent
   â†“
Memory Learning
   â†“
Final Debug Output

ğŸ¤– Agents in the System
1ï¸âƒ£ Error Analyst

Extracts exception type

Identifies domain

Predicts root cause signals

2ï¸âƒ£ Retrieval Strategist

Plans search depth

Expands queries

Chooses retrieval strategy

3ï¸âƒ£ Fix Generator

Produces multiple solution approaches

Recommends best fix

Provides step-by-step actions

4ï¸âƒ£ Solution Validator

Reviews fix correctness

Checks logical consistency

Adds reviewer feedback

5ï¸âƒ£ Memory Agent

Stores past debugging sessions

Retrieves similar past errors

Improves system performance over time

ğŸ” Tech Stack
AI / ML

Retrieval Augmented Generation (RAG)

Sentence Transformers

FAISS vector search

Cross-Encoder reranking

Multi-agent orchestration

Backend

Python

Groq / LLM APIs

Modular agent architecture

ğŸ“Š Key Features

âœ” Multi-agent reasoning pipeline
âœ” Vector similarity search
âœ” Cross-encoder reranking
âœ” Solution validation layer
âœ” Memory-based learning
âœ” Structured debugging outputs

ğŸ§ª Example Output
ROOT CAUSE:
Modifying collection while iterating over it

RECOMMENDED FIX:
Use Iterator

QUICK STEPS:
- Create iterator
- Replace loop
- Use iterator.remove()

VALIDATION:
Root cause valid: True
Fix correct: True
Reviewer note: Recommended fix is safe and appropriate

ğŸ§  Learning Capability

The system stores:

past errors

successful fixes

validation confidence

Future similar errors trigger:

MEMORY HIT FOUND


and reuse learned solutions instantly.

ğŸ’¼ Why this project matters

This is not a chatbot.

It demonstrates:

AI system architecture

retrieval planning

reasoning agents

ML feedback loops

production-style debugging assistant design

Suitable for roles in:

Generative AI Engineering

Machine Learning Engineering

Applied AI

AI Platform Engineering

ğŸ› ï¸ How to Run
1ï¸âƒ£ Clone repo
git clone <repo-url>
cd ai-debugger

2ï¸âƒ£ Create virtual environment
python -m venv .venv
source .venv/Scripts/activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add API key

Create .env

GROQ_API_KEY=your_key_here

5ï¸âƒ£ Run app
python app.py

ğŸ“Œ Future Improvements

Streamlit UI

Real-time IDE plugin

Codebase-level debugging

Performance benchmarking

Reinforcement learning for fix ranking

ğŸ‘©â€ğŸ’» Author

Built as part of AI engineering and ML portfolio.

Focus areas:

Multi-agent AI systems

Retrieval-based reasoning

Learning copilots

Developer productivity AI

â­ If you found this useful

Star the repo â€” it helps visibility and supports the project.
